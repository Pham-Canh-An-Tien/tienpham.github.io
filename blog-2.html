<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Blog</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: DevFolio - v4.8.1
  * Template URL: https://bootstrapmade.com/devfolio-bootstrap-portfolio-html-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex align-items-center justify-content-between">

      <h1 class="logo"><a href="index.html">Tien Pham</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto active" href="#hero">Home</a></li>
          <li><a class="nav-link scrollto" href="#about">About</a></li>
          <li><a class="nav-link scrollto" href="#services">Education</a></li>
          <li><a class="nav-link scrollto " href="#work">Project</a></li>
          <li><a class="nav-link scrollto " href="#blog">Publications</a></li>
          <li><a class="nav-link scrollto" href="#contact">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <div class="hero hero-single route bg-image" style="background-image: url(assets/img/background.jpg)">
    <div class="overlay-mf"></div>
    <div class="hero-content display-table">
      <div class="table-cell">
        <div class="container">
          <h2 class="hero-title mb-4">Image classification with Convolutional Neural Network using Google Colab and Caltech101 Dataset</h2>
        </div>
      </div>
    </div>
  </div>

  <main id="main">

    <!-- ======= Blog Single Section ======= -->
    <section class="blog-wrapper sect-pt4" id="blog">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <div class="post-box">
              <div class="post-thumb">
                <!-- <img src="assets/img/kaggle1/titanic.jpg" class="img-fluid" alt=""> -->
              </div>
              <div class="post-meta">
                <h1 class="article-title">This blog will introduce the step-by-step tutorial for Machine Learning beginners to develop the image classification model using Google Colab 
                  and opensource Dataset.
                </h1>
                <ul>
                  <li>
                    <span class="bi bi-person"></span>
                    <a href="/index.html">Tien Pham</a>
                  </li>
                  <li>
                    <span class="bi bi-tag"></span>
                    <a href="https://www.kaggle.com/code/tienapham/draft-10-05/data?scriptVersionId=107442102">Image Classification</a>
                  </li>
                  <li>
                    <span class="bi bi-tag"></span>
                    <a href="https://www.kaggle.com/code/tienapham/draft-10-05/data?scriptVersionId=107442102">Convolutional Neural Network</a>
                  </li>
                </ul>
              </div>
              <div class="article-content">
                <h1 class="article-title">Introduction</h1>
                <p>
                  Machine Learning and Deep learning have been popular over a decay with a significant progress in both Research and Industry.
                  However, it requires some background knowledges in terms of probabilistic and mathematic concepts as well as the coding languages and platforms that can be used.
                  In this tutorial, we will go thought the whole process to build the classification model using deep learning. This tutorial will hopefully help the beginners 
                  to approach the Deep Learning field in the easiest way. 
                </p>
                <p>
                  First of all, we have to understand what is machine learning and deep learning and why we use it for classification problems.
                  <b>Machine Learning</b> is a general concept for the use of computer that are able to perform a specific task wiout following explicit
                  instructions [1]. We can apply implicit algorithms with statistical model to analyze and build the mathematical interference from patterns in data.
                  For further learning curves in Machine Learning, I would suggest to read <a href="https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413/ref=asc_df_1449369413/?tag=hyprod-20&linkCode=df0&hvadid=312280575053&hvpos=&hvnetw=g&hvrand=10139238590813693336&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9027195&hvtargid=pla-423142395481&psc=1"><b>Introduction
                    to Machine Learning with Python</b></a>. 
                </p>
                <p>
                  <b>Python</b> is well-known for the Data Science and Machine Learning Engineer, which supports various useful tools and libraries for
                  building and analyzing the model as well as evaluating the performance. In this example, we will use the Jupiter Notebook working in Google Colab
                  for GPU supports. GPU will help us with faster operation implementation for Machine Learning application comparing to CPU [2]. Most of the training
                  workload will be implemented on GPU. 
                </p>
                <p>
                  <a href="https://www.kaggle.com/"><b>Kaggle</b></a> is a biggest Data Science community where we can access to multiple opensource dataset. Furthermore, it also supports to imports the dataset
                  to Jupiter Notebook in Google Colab.  
                </p>
                <p>That's it for the introduction, now we have a basic understanding about what we will do in this tutorial. Let's start !!!</p>
                
                <h1 class="article-title">Data Processing</h1>
                In <a href="https://colab.research.google.com/"><b>Google Colab</b></a>, create a Jupiter Notebook and import the libraries. This tutorial will use
                <a href="https://www.tensorflow.org/">Tensorflow</a> library to build the model.

                  <div class="post-thumb">
                    <img src="assets/img/kaggle2/1.jpg" width = "1200">
                  </div>
                <p>
                  In our kaggle profile, we have to export API token that contains our identity to access the dataset.
                  <img src="assets/img/kaggle2/2.jpg" width = "1200">
                </p>
                <p>
                  We can install Kaggle, import the kaggle.json file and download the dataset. The dataset will includes 1661 images
                  belonging to 3 classes ("Motobikes", "Airplanes", "Schooner").
                  <img src="assets/img/kaggle2/3.jpg" width = "1200">
                </p>
                <p>
                  Let's configure and load our dataset as image below:
                  <img src="assets/img/kaggle2/4.jpg" width = "1200">
                  <b>Batchsize</b> is the number of image we can load for each computational iteration. It will depend on the RAM we have
                  in our server. However, we should fully utilize the RAM to load as much sample as possible in one batch. The reason
                  is that the model will learn each batch separatedly and the machine will have multiple overhead to run large number of batches 
                  while the connection between the sample from different batches will not be seen in model training.
                </p>
                <p><b>Epoch</b>, on the other hand, is a number of passes the whole training data is go through. Ideally, the larger epoch, the more fitting the model will be.
                Therefore, we have to manage the epoch value so that the model will not be underfitting or overfitting.
                </p>
                <img src="assets/img/kaggle2/Presentation1.gif" width = "1200">
                <p><b>Dataset Loading</b> is also an important step where we devide the whole dataset into training data and validating data.
                  As a common practice in Machine Learning, the ratio would be 80:20 which mean 80% of data is used for training and 20% of 
                  data is used for validation. The images may vary in resolution, which causes the critical problem in model building where the size
                  of each matrix is different. Thus, we have to scale all images in to the same size as defined. We can look at some samples in the 
                  dataset to see the configuration.
                  </p>
                  <img src="assets/img/kaggle2/5.jpg" width = "1200">
                  <img src="assets/img/kaggle2/6.jpg" width = "1200">
                  <p><b>Dataset Shuffle</b> is a preprocessing step where we want the distribution of the data is randomly.
                  </p>
                  <p>
                    Now we already have the datasets, let try to build the convolutional neural network to classify the images.
                    At this stage, I will assume that we already know the basic concept of CNN including <b>Kernel, convolution layers, regulation layer, 
                      and dense layer</b>. For those who need to understand these concepts, I would suggest reading the references [3]. First of all, we will create the <b>backbone architecture</b>
                      of our model. Backbone Architecture is the layout of network including number of convolution layers, how the layers are connected, what is the filter size, etc.
                      We can refer some famous CNN model such as VGG, GoogleNet, ResNet, etc. However, this problem is too small to use the famous backbones (we have only 3 classes). I will
                      start building everything randomely.
                  </p>
                  <img src="assets/img/kaggle2/7.jpg" width = "1200">
                  <p>As you can see, we have 2 convolution layers with the Maxpooling after each evolution. following that is the flatten layer to convert all the features
                    into 1 vector, following is the fully connected neural network to classify the images base on the features. To see the model configuration, we can use model.summary().
                  </p>
                  <img src="assets/img/kaggle2/8.jpg" width = "1200">
                  <p>
                    After going through the convolution layers, we will have 100352 features that is used to classify the images. Let's start training and validate the 
                    performance of model.
                  </p>
                  <img src="assets/img/kaggle2/9.jpg" width = "1200">
                  <img src="assets/img/kaggle2/10.jpg" width = "1200">
                  <p>
                    Well, our model seems perform very well with accuracy upto 0.994. This is awesome for the first try!!! Let plot the error durign training and the performance to see
                    what actually happened.
                  </p>
                  <img src="assets/img/kaggle2/11.jpg" width = "1200">
                  <img src="assets/img/kaggle2/12.jpg" width = "1200">
                  <p>
                    The loss of training and validating seem converse very well. Let try to increase the model size (add one more convolution layer into the model)
                    to see what happen
                  </p>
                  <img src="assets/img/kaggle2/13.jpg" width = "1200">
                  <img src="assets/img/kaggle2/14.jpg" width = "1200">
                  <p>
                    Now the number of features after convolution layers reduces to 50176. The reduction caused by one more filter is added so that the 
                    features is now more generic.
                  </p>
                  <img src="assets/img/kaggle2/15.jpg" width = "1200">
                  <img src="assets/img/kaggle2/16.jpg" width = "1200">
                  <p>
                    The accuracy on validation increase by 0.3%. let add one more layer !!!!
                  </p>
                  <img src="assets/img/kaggle2/17.jpg" width = "1200">
                  <img src="assets/img/kaggle2/18.jpg" width = "1200">
                  <p>
                    The more layer we add in, the less features we have after convolution. But <b>is it mean that the model is smaller?</b> Let run it to see.
                  </p>
                  <img src="assets/img/kaggle2/19.jpg" width = "1200">
                  <img src="assets/img/kaggle2/20.jpg" width = "1200">
                  <p>
                    The time that we spend to train model each epoch actually longer in this test (from 1s to 2s). Yes, the problem here is we add one more layer
                    which increase the computational cost significantly. Although the dense network size reduced, but most of computational cost happen in convolution layers.
                    Furthermore, <b>The accuracy decreased</b>. 
                  </p>
                  <img src="assets/img/kaggle2/21.jpg" width = "1200">
                  <p>
                    Looking at the Loss during training and validation, we can see that there is always a gap between the two set. Now let try to increase the epoch to 50 to see if it actually help.
                  </p>
                  <img src="assets/img/kaggle2/22.jpg" width = "1200">
                  <p>
                    <b>Excellent!!!</b>, we can classify the images correctly. But this is not always the case. Let me try to run the model one more time.
                  </p>
                  <img src="assets/img/kaggle2/23.jpg" width = "1200">
                  <p>
                    Performance is different with previous time. <b>Why that is the case?</b>. Well, the model will strongly depend on how we initialize the value of it.
                    So in two different runs, the first model can converge very well why the second run, the model is not that good. But the performance is not that big.
                    I also try with the bigger batch size (64) to see how it affect the model.
                  </p>
                  <img src="assets/img/kaggle2/24.jpg" width = "1200">
                  <p>
                    As a result, number of step in one epoch reduce by half, but each step will consume more time to train the model (approximately double) and the total
                    time is still the same. However, this is not the case where we train with our server because the loading time is much longer from disk, so bigger batchsize will 
                    help reduce the training time.
                    <h1 class="article-title">Data Augumentation</h1>
                  </p>
                  Notice that the training accuracy is always 1.00 while the validation accuracy varies from multiple trials. In an effort to trying reduce that overfitting,
                  I find a technique called <b>Data Augumentation</b> to increase a dataset size and increase the randomeness of objects []. We can either <b>Rotate, Zoom</b>
                  or <b>Flip</b> the images to receive the new images that still represent for the same objects 
                  <p>
                    <img src="assets/img/kaggle2/25.jpg" width = "1200">
                    <img src="assets/img/kaggle2/26.jpg" width = "1200">
                    As we can see, the Airplane now is showed in multiple angles, which will increase the randomness of the data. According to TensorFlow [3], we have 2 ways to augument data
                    <ul>
                      <li>Augument data at the preprocessing data in our dataset</li>
                      <li>Augument data as a part of our model</li>
                    </ul>
                    In our case, we will use the second option that will benefit the GPU accerelation.
                  </p>
                  <img src="assets/img/kaggle2/27.jpg" width = "1200">
                  <img src="assets/img/kaggle2/28.jpg" width = "1200">
                  <p>
                    The loss of training set is now not always 1.00 because we gradually add the new samples (from augumentation) into the data set, so that it will increase the generalization
                    of the model.
                  </p>

                  <h1 class="article-title">Conclusion</h1>
                  <p>
                    This blog shows you how to build a basic CNN model for image classification on Google Colab. The code for this tutorial can be found <a href="https://github.com/Pham-Canh-An-Tien/data-mining/blob/main/Image_Classification.ipynb"><b>here</b></a>.
                    We already learn some basic concept of hyperparameter such as Batch and Epoches. How it affect the model and how to build our model from scratch.
                    The model can classify the images in Caltech101 dataset with accuracy of 99%. We also examine the data Augmentation Teniques to increase a datasize and reduce the overfitting.
                  </p>
                  <h1 class="article-title">Contribution</h1>
                  <p>
                    The Notebook have been developed by Tien Pham with the references listed below (Mostly from Tensorflow and some forum such as kaggle to debug and feed the data into Google 
                    Colab). My contributions are listed below:
                    <li>
                      Although most of the code is referred from TensorFlow with some modifications, I tried to understand the concepts and explain it in an easier way
                      including: <b>Batch size, Epoch, backbone architecture</b> and <b>Data Augumentation</b>.
                    </li>
                    <li>
                      I do design the model from scratch with the experiments on how layer affect the model performance and computational cost. The model can classify with the accuracy of 99%.
                    </li>
                    <li>
                      I also try to improve the generalization of the model by applying Data Augmentation. Although this model is not the best, hopefully I will have chance to work more on it in the future.
                    </li>
                    <li>
                      A full tutorial for beginners starting building a CNN for image classification with explaination.
                    </li>
                  </p>
                  <h1 class="article-title">References</h1>
                  <p>
                    [1]. Müller, Andreas C., and Sarah Guido. Introduction to machine learning with Python: a guide for data scientists. " O'Reilly Media, Inc.", 2016.
                  </p>
                  <p>
                    [2]. Schlegel, Daniel. "Deep machine learning on Gpu." University of Heidelber-Ziti 12 (2015).</a>
                  </p>
                  <p>
                    [3]. <a href="https://www.tensorflow.org/tutorials/images/cnn"> TensorFlow.</a>
                  </p>
                  <p>
                    [4]. Deng, Jia, et al. "Imagenet: A large-scale hierarchical image database." 2009 IEEE conference on computer vision and pattern recognition. Ieee, 2009.</a>
                  </p>
              </div>
            </div>
          
        
        </div>
      </div>
    </section><!-- End Blog Single Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-sm-12">
          <div class="copyright-box">
            <p class="copyright">&copy; Copyright <strong>Tien Pham</strong>. All Rights Reserved</p>
            <div class="credits">
              <!--
              All the links in the footer should remain intact.
              You can delete the links only if you purchased the pro version.
              Licensing information: https://bootstrapmade.com/license/
              Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=DevFolio
            -->
              <!-- Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>